import streamlit as st
import pandas as pd
from sqlalchemy import create_engine
import plotly.express as px
import google.generativeai as genai

# 1. Cáº¤U HÃŒNH TRANG
st.set_page_config(page_title="Cinema Analytics Capstone", layout="wide", page_icon="ğŸ¬")
st.title("ğŸ¬ Há»‡ Thá»‘ng PhÃ¢n TÃ­ch Doanh Thu & GenAI")
st.markdown("*Capstone Project - ETL Pipeline & AI Integration*")

# 2. Káº¾T Ná»I DATABASE
@st.cache_resource
def get_connection():
    return create_engine(st.secrets["DB_URL"])

# --- Sá»¬A á» ÄÃ‚Y: KHÃ”NG DÃ™NG Tá»° DÃ’ Ná»®A ---
# Thay 'movies_fact' báº±ng tÃªn báº£ng tháº­t chá»©a 45k dÃ²ng trÃªn Neon cá»§a báº¡n
current_table = "ratings" 

# --- SIDEBAR: UPLOAD Dá»® LIá»†U ---
with st.sidebar:
    st.header("ğŸ“¥ Náº¡p dá»¯ liá»‡u má»›i")
    uploaded_file = st.file_uploader("Chá»n file CSV phim má»›i", type=["csv"])
    
    if uploaded_file is not None:
        if st.button("LÆ°u vÃ o Database"):
            try:
                df_new = pd.read_csv(uploaded_file)
                # Load vÃ o Ä‘Ãºng báº£ng current_table
                df_new.to_sql(current_table, get_connection(), if_exists='append', index=False)
                st.success(f"âœ… ÄÃ£ thÃªm {len(df_new)} dÃ²ng vÃ o báº£ng '{current_table}'!")
                st.cache_data.clear() 
                st.rerun()
            except Exception as e:
                st.error(f"Lá»—i Upload: {e}")

# 3. LOAD Dá»® LIá»†U
@st.cache_data
def load_data():
    engine = get_connection()
    # TÄƒng limit lÃªn 10000 Ä‘á»ƒ xem cho Ä‘Ã£
    query = f"SELECT * FROM {current_table} LIMIT 10000"
    df = pd.read_sql(query, engine)
    return df

try:
    df = load_data()
except Exception as e:
    st.error(f"Lá»—i Ä‘á»c báº£ng '{current_table}': {e}. HÃ£y kiá»ƒm tra láº¡i tÃªn báº£ng trÃªn Neon!")
    st.stop()

# 4. GIAO DIá»†N DASHBOARD
tab1, tab2 = st.tabs(["ğŸ“Š BÃ¡o CÃ¡o & Biá»ƒu Äá»“", "ğŸ¤– Trá»£ lÃ½ AI"])

with tab1:
    st.header(f"Dá»¯ liá»‡u tá»« báº£ng: {current_table}")
    
    # KPI
    c1, c2, c3 = st.columns(3)
    c1.metric("Tá»•ng sá»‘ phim", f"{len(df):,}")
    
    if 'revenue' in df.columns:
         c2.metric("Tá»•ng Doanh Thu", f"${df['revenue'].sum():,.0f}")
    
    rating_col = 'vote_average' if 'vote_average' in df.columns else ('rating' if 'rating' in df.columns else None)
    if rating_col:
         c3.metric("Äiá»ƒm Ä‘Ã¡nh giÃ¡ TB", f"{df[rating_col].mean():.2f}")

    st.divider()
    
    # Chart
    col_chart1, col_chart2 = st.columns(2)
    with col_chart1:
        st.subheader("PhÃ¢n bá»‘ Ä‘iá»ƒm Ä‘Ã¡nh giÃ¡")
        if rating_col:
            fig1 = px.histogram(df, x=rating_col, nbins=20)
            st.plotly_chart(fig1, use_container_width=True)
    
    with col_chart2:
        st.subheader("Top Doanh Thu")
        rev_col = 'revenue' if 'revenue' in df.columns else None
        title_col = 'title' if 'title' in df.columns else ('original_title' if 'original_title' in df.columns else None)
        if rev_col and title_col:
            top_df = df.nlargest(10, rev_col)
            fig2 = px.bar(top_df, y=title_col, x=rev_col, orientation='h')
            st.plotly_chart(fig2, use_container_width=True)

    with st.expander("Xem dá»¯ liá»‡u chi tiáº¿t"):
        st.dataframe(df)

with tab2:
    st.header("Chatbot AI")
    if "GEMINI_API_KEY" in st.secrets:
        genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
        model = genai.GenerativeModel('models/gemini-2.0-flash')
        
        if "messages" not in st.session_state:
            st.session_state.messages = []
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

        if prompt := st.chat_input("Há»i vá» phim..."):
            st.chat_message("user").markdown(prompt)
            st.session_state.messages.append({"role": "user", "content": prompt})
            try:
                # Láº¥y máº«u 5 dÃ²ng
                data_context = df.head(5).to_string()
                full_prompt = f"Data:\n{data_context}\nQ: {prompt}"
                response = model.generate_content(full_prompt)
                st.chat_message("assistant").markdown(response.text)
                st.session_state.messages.append({"role": "assistant", "content": response.text})
            except Exception as e:
                st.error(f"Lá»—i AI: {e}")
